{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZDngNBfQYcJu2/gm6UI8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshit060/bot-detection-/blob/main/RGCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVpq0XKqdBZB",
        "outputId": "0eeec484-a46f-440a-b6fe-6ba660a17084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "TORCH = format_pytorch_version(torch.__version__)\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "CUDA = format_cuda_version(torch.version.cuda)\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric networkx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGr7dPzmdNed",
        "outputId": "54140371-2f25-44c1-c350-4e19d3e4152c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt28cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-cluster) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92RLDizA1Wcl",
        "outputId": "367180ca-c006-4d9b-abb9-38f7446b1c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl size=3807827 sha256=0aa51cb16218482297b60f67c1bfb0de90e917f3edd51b1ef2319ce69fc17c95\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/20/50/44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl size=2906575 sha256=6bbc3ad3927850bb082df645a4f924db264ecf6d421e2c4aba738c1a9028921f\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/fa/21/bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
            "Successfully built torch-scatter torch-sparse\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0 torch-scatter-2.1.2 torch-sparse-0.6.18\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torch-geometric torch-scatter torch-sparse --extra-index-url https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
        "!pip install scikit-learn pandas numpy tqdm matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "import torch_scatter\n",
        "import torch_sparse\n",
        "\n",
        "# 1. Check module imports\n",
        "print(\"PyTorch Geometric Modules Status:\")\n",
        "print(f\"torch_geometric imported: {torch_geometric.__version__}\")\n",
        "print(f\"torch_scatter imported: {torch_scatter.__version__}\")\n",
        "print(f\"torch_sparse imported: {torch_sparse.__version__}\")\n",
        "\n",
        "# 2. Check CUDA/GPU status\n",
        "print(\"\\nCUDA/GPU Status:\")\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"Running on CPU. Change runtime type to GPU for speed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbeq1Vvb1aZd",
        "outputId": "ee0b6447-f938-417f-ab38-ec73b890ada7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Geometric Modules Status:\n",
            "torch_geometric imported: 2.7.0\n",
            "torch_scatter imported: 2.1.2\n",
            "torch_sparse imported: 0.6.18\n",
            "\n",
            "CUDA/GPU Status:\n",
            "CUDA available: True\n",
            "GPU Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure we are in the RF-GNN root directory\n",
        "%cd /content/RF-GNN/\n",
        "\n",
        "# Clean up any previously failed links/folders\n",
        "!rm -rf Data/MGTAB\n",
        "\n",
        "# Re-create the correct symbolic link: Data/MGTAB -> /content/drive/MyDrive/1. MGTAB\n",
        "!ln -s /content/drive/MyDrive/1.\\ MGTAB Data/MGTAB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZxrkPS-F8BF",
        "outputId": "e491e04a-9eea-4ba1-d21e-233a509b11bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RF-GNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Change directory to the RF-GNN root\n",
        "%cd /content/RF-GNN/\n",
        "\n",
        "# 2. Patch the logging lines by removing the problematic .item() calls\n",
        "!sed -i 's/\\.item()//g' RF-GNN.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ7v96VCR2db",
        "outputId": "a3c40c7f-9bef-4a9d-d358-abb7b4809071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RF-GNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python RF-GNN.py -dataset MGTAB -model GCN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqx3s4ZyTo0h",
        "outputId": "bead35de-78b4-4a3d-9970-938688c72366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(dataset='MGTAB', model='GCN', labelrate=0.1)\n",
            "relation used: followers  friends  traning 1th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1257 acc_train: 0.9176 acc_val: 0.8471\n",
            "Epoch: 0200 loss_train: 0.0243 acc_train: 0.9421 acc_val: 0.8314\n",
            "acc_test 0.8598 f1_test: 0.8227 precision_test: 0.8238 recall_test: 0.8216\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1051 acc_train: 0.9195 acc_val: 0.8549\n",
            "Epoch: 0200 loss_train: 0.1429 acc_train: 0.9087 acc_val: 0.8500\n",
            "acc_test 0.8379 f1_test: 0.7828 precision_test: 0.7690 recall_test: 0.8025\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.0846 acc_train: 0.9254 acc_val: 0.8588\n",
            "Epoch: 0200 loss_train: 0.3234 acc_train: 0.8665 acc_val: 0.8196\n",
            "acc_test 0.8451 f1_test: 0.7968 precision_test: 0.7876 recall_test: 0.8083\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.0874 acc_train: 0.9195 acc_val: 0.8471\n",
            "Epoch: 0200 loss_train: 1.2366 acc_train: 0.7694 acc_val: 0.7569\n",
            "acc_test 0.8531 f1_test: 0.8143 precision_test: 0.8155 recall_test: 0.8131\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.0932 acc_train: 0.9244 acc_val: 0.8490\n",
            "Epoch: 0200 loss_train: 0.0634 acc_train: 0.9254 acc_val: 0.8510\n",
            "acc_test 0.8662 f1_test: 0.8227 precision_test: 0.8097 recall_test: 0.8397\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1272 acc_train: 0.9078 acc_val: 0.8520\n",
            "Epoch: 0200 loss_train: 0.0492 acc_train: 0.9293 acc_val: 0.8500\n",
            "acc_test 0.8631 f1_test: 0.8230 precision_test: 0.8171 recall_test: 0.8297\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1829 acc_train: 0.8871 acc_val: 0.8363\n",
            "Epoch: 0200 loss_train: 0.0564 acc_train: 0.9166 acc_val: 0.8471\n",
            "acc_test 0.8491 f1_test: 0.8023 precision_test: 0.7932 recall_test: 0.8136\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1142 acc_train: 0.9097 acc_val: 0.8412\n",
            "Epoch: 0200 loss_train: 0.1588 acc_train: 0.8940 acc_val: 0.8510\n",
            "acc_test 0.8373 f1_test: 0.7959 precision_test: 0.7995 recall_test: 0.7926\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1493 acc_train: 0.8911 acc_val: 0.8216\n",
            "Epoch: 0200 loss_train: 0.0037 acc_train: 0.9441 acc_val: 0.8412\n",
            "acc_test 0.8450 f1_test: 0.8040 precision_test: 0.8051 recall_test: 0.8029\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1188 acc_train: 0.9048 acc_val: 0.8412\n",
            "Epoch: 0200 loss_train: 0.0920 acc_train: 0.9176 acc_val: 0.8441\n",
            "acc_test 0.8510 f1_test: 0.8095 precision_test: 0.8072 recall_test: 0.8119\n",
            "Round:0001 acc_test 0.8673 f1_test: 0.8285 precision_test: 0.8228 recall_test: 0.8350\n",
            "traning 2th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1076 acc_train: 0.9019 acc_val: 0.8598\n",
            "Epoch: 0200 loss_train: 0.0861 acc_train: 0.9048 acc_val: 0.8667\n",
            "acc_test 0.8578 f1_test: 0.8079 precision_test: 0.7915 recall_test: 0.8314\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1046 acc_train: 0.8970 acc_val: 0.8500\n",
            "Epoch: 0200 loss_train: 0.0334 acc_train: 0.9215 acc_val: 0.8471\n",
            "acc_test 0.8382 f1_test: 0.7786 precision_test: 0.7612 recall_test: 0.8060\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.2181 acc_train: 0.8685 acc_val: 0.8637\n",
            "Epoch: 0200 loss_train: 0.0611 acc_train: 0.9176 acc_val: 0.8765\n",
            "acc_test 0.8721 f1_test: 0.8365 precision_test: 0.8356 recall_test: 0.8375\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1617 acc_train: 0.8862 acc_val: 0.8451\n",
            "Epoch: 0200 loss_train: 0.2208 acc_train: 0.8862 acc_val: 0.8775\n",
            "acc_test 0.8667 f1_test: 0.8248 precision_test: 0.8154 recall_test: 0.8363\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.4084 acc_train: 0.7998 acc_val: 0.7941\n",
            "Epoch: 0200 loss_train: 0.0750 acc_train: 0.9087 acc_val: 0.8637\n",
            "acc_test 0.8522 f1_test: 0.8048 precision_test: 0.7945 recall_test: 0.8178\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1245 acc_train: 0.8940 acc_val: 0.8588\n",
            "Epoch: 0200 loss_train: 0.0569 acc_train: 0.9087 acc_val: 0.8676\n",
            "acc_test 0.8544 f1_test: 0.8171 precision_test: 0.8218 recall_test: 0.8129\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.2005 acc_train: 0.8489 acc_val: 0.8392\n",
            "Epoch: 0200 loss_train: 0.1405 acc_train: 0.8822 acc_val: 0.8353\n",
            "acc_test 0.8279 f1_test: 0.7487 precision_test: 0.7230 recall_test: 0.8097\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1834 acc_train: 0.8626 acc_val: 0.8461\n",
            "Epoch: 0200 loss_train: 0.0840 acc_train: 0.9146 acc_val: 0.8569\n",
            "acc_test 0.8520 f1_test: 0.7958 precision_test: 0.7755 recall_test: 0.8289\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1628 acc_train: 0.8822 acc_val: 0.8784\n",
            "Epoch: 0200 loss_train: 1.9026 acc_train: 0.7488 acc_val: 0.7461\n",
            "acc_test 0.8658 f1_test: 0.8252 precision_test: 0.8183 recall_test: 0.8332\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1241 acc_train: 0.8979 acc_val: 0.8500\n",
            "Epoch: 0200 loss_train: 0.1094 acc_train: 0.8999 acc_val: 0.8608\n",
            "acc_test 0.8536 f1_test: 0.7977 precision_test: 0.7769 recall_test: 0.8319\n",
            "Round:0002 acc_test 0.8695 f1_test: 0.8251 precision_test: 0.8102 recall_test: 0.8455\n",
            "traning 3th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.0984 acc_train: 0.9195 acc_val: 0.8627\n",
            "Epoch: 0200 loss_train: 0.0529 acc_train: 0.9215 acc_val: 0.8598\n",
            "acc_test 0.8474 f1_test: 0.8131 precision_test: 0.8266 recall_test: 0.8030\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1345 acc_train: 0.9068 acc_val: 0.8382\n",
            "Epoch: 0200 loss_train: 0.0507 acc_train: 0.9195 acc_val: 0.8412\n",
            "acc_test 0.8494 f1_test: 0.8150 precision_test: 0.8276 recall_test: 0.8053\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1122 acc_train: 0.9078 acc_val: 0.8422\n",
            "Epoch: 0200 loss_train: 0.0382 acc_train: 0.9244 acc_val: 0.8422\n",
            "acc_test 0.8528 f1_test: 0.8068 precision_test: 0.7983 recall_test: 0.8170\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1055 acc_train: 0.9048 acc_val: 0.8490\n",
            "Epoch: 0200 loss_train: 0.0562 acc_train: 0.9195 acc_val: 0.8422\n",
            "acc_test 0.8637 f1_test: 0.8220 precision_test: 0.8145 recall_test: 0.8307\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.1391 acc_train: 0.8950 acc_val: 0.8431\n",
            "Epoch: 0200 loss_train: 0.0387 acc_train: 0.9323 acc_val: 0.8539\n",
            "acc_test 0.8631 f1_test: 0.8239 precision_test: 0.8210 recall_test: 0.8269\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1733 acc_train: 0.8960 acc_val: 0.8255\n",
            "Epoch: 0200 loss_train: 0.1271 acc_train: 0.9117 acc_val: 0.8324\n",
            "acc_test 0.8636 f1_test: 0.8286 precision_test: 0.8336 recall_test: 0.8241\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1608 acc_train: 0.8705 acc_val: 0.8216\n",
            "Epoch: 0200 loss_train: 0.1652 acc_train: 0.8724 acc_val: 0.8422\n",
            "acc_test 0.8654 f1_test: 0.8176 precision_test: 0.8001 recall_test: 0.8429\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.2113 acc_train: 0.8616 acc_val: 0.8069\n",
            "Epoch: 0200 loss_train: 0.1384 acc_train: 0.9019 acc_val: 0.8441\n",
            "acc_test 0.8592 f1_test: 0.8208 precision_test: 0.8215 recall_test: 0.8202\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1472 acc_train: 0.9009 acc_val: 0.8480\n",
            "Epoch: 0200 loss_train: 0.0530 acc_train: 0.9244 acc_val: 0.8549\n",
            "acc_test 0.8685 f1_test: 0.8279 precision_test: 0.8196 recall_test: 0.8376\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1108 acc_train: 0.8901 acc_val: 0.8176\n",
            "Epoch: 0200 loss_train: 0.0659 acc_train: 0.9117 acc_val: 0.8216\n",
            "acc_test 0.8515 f1_test: 0.8076 precision_test: 0.8028 recall_test: 0.8129\n",
            "Round:0003 acc_test 0.8766 f1_test: 0.8409 precision_test: 0.8371 recall_test: 0.8449\n",
            "traning 4th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1099 acc_train: 0.9038 acc_val: 0.8637\n",
            "Epoch: 0200 loss_train: 0.2438 acc_train: 0.8940 acc_val: 0.8490\n",
            "acc_test 0.8488 f1_test: 0.8063 precision_test: 0.8017 recall_test: 0.8113\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1346 acc_train: 0.9028 acc_val: 0.8647\n",
            "Epoch: 0200 loss_train: 0.0323 acc_train: 0.9352 acc_val: 0.8569\n",
            "acc_test 0.8474 f1_test: 0.8010 precision_test: 0.7917 recall_test: 0.8127\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1588 acc_train: 0.8940 acc_val: 0.8529\n",
            "Epoch: 0200 loss_train: 0.1128 acc_train: 0.9166 acc_val: 0.8588\n",
            "acc_test 0.8414 f1_test: 0.7872 precision_test: 0.7716 recall_test: 0.8106\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.2938 acc_train: 0.8391 acc_val: 0.8127\n",
            "Epoch: 0200 loss_train: 0.0554 acc_train: 0.9185 acc_val: 0.8647\n",
            "acc_test 0.8466 f1_test: 0.8062 precision_test: 0.8057 recall_test: 0.8066\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.0918 acc_train: 0.9087 acc_val: 0.8569\n",
            "Epoch: 0200 loss_train: 0.0734 acc_train: 0.9058 acc_val: 0.8500\n",
            "acc_test 0.8582 f1_test: 0.8177 precision_test: 0.8119 recall_test: 0.8243\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1064 acc_train: 0.9156 acc_val: 0.8578\n",
            "Epoch: 0200 loss_train: 0.0822 acc_train: 0.9185 acc_val: 0.8608\n",
            "acc_test 0.8451 f1_test: 0.7942 precision_test: 0.7805 recall_test: 0.8135\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1604 acc_train: 0.8891 acc_val: 0.8431\n",
            "Epoch: 0200 loss_train: 0.0410 acc_train: 0.9254 acc_val: 0.8588\n",
            "acc_test 0.8445 f1_test: 0.7955 precision_test: 0.7843 recall_test: 0.8103\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.0785 acc_train: 0.9254 acc_val: 0.8559\n",
            "Epoch: 0200 loss_train: 0.0315 acc_train: 0.9352 acc_val: 0.8520\n",
            "acc_test 0.8533 f1_test: 0.8048 precision_test: 0.7901 recall_test: 0.8255\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1186 acc_train: 0.8979 acc_val: 0.8578\n",
            "Epoch: 0200 loss_train: 0.1005 acc_train: 0.9038 acc_val: 0.8559\n",
            "acc_test 0.8474 f1_test: 0.8092 precision_test: 0.8121 recall_test: 0.8066\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1199 acc_train: 0.9097 acc_val: 0.8686\n",
            "Epoch: 0200 loss_train: 0.0592 acc_train: 0.9293 acc_val: 0.8647\n",
            "acc_test 0.8528 f1_test: 0.8047 precision_test: 0.7909 recall_test: 0.8240\n",
            "Round:0004 acc_test 0.8608 f1_test: 0.8183 precision_test: 0.8083 recall_test: 0.8309\n",
            "traning 5th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1425 acc_train: 0.8930 acc_val: 0.8559\n",
            "Epoch: 0200 loss_train: 0.0437 acc_train: 0.9254 acc_val: 0.8627\n",
            "acc_test 0.8612 f1_test: 0.8228 precision_test: 0.8198 recall_test: 0.8259\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1154 acc_train: 0.8979 acc_val: 0.8784\n",
            "Epoch: 0200 loss_train: 0.1092 acc_train: 0.9107 acc_val: 0.8804\n",
            "acc_test 0.8618 f1_test: 0.8331 precision_test: 0.8501 recall_test: 0.8211\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1346 acc_train: 0.8970 acc_val: 0.8480\n",
            "Epoch: 0200 loss_train: 0.0251 acc_train: 0.9215 acc_val: 0.8373\n",
            "acc_test 0.8469 f1_test: 0.8059 precision_test: 0.8051 recall_test: 0.8068\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.0947 acc_train: 0.9127 acc_val: 0.8676\n",
            "Epoch: 0200 loss_train: 0.0689 acc_train: 0.9225 acc_val: 0.8686\n",
            "acc_test 0.8587 f1_test: 0.8257 precision_test: 0.8343 recall_test: 0.8186\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.1329 acc_train: 0.9019 acc_val: 0.8578\n",
            "Epoch: 0200 loss_train: 0.1273 acc_train: 0.9127 acc_val: 0.8696\n",
            "acc_test 0.8515 f1_test: 0.8095 precision_test: 0.8052 recall_test: 0.8142\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1652 acc_train: 0.8970 acc_val: 0.8549\n",
            "Epoch: 0200 loss_train: 0.2210 acc_train: 0.8773 acc_val: 0.8510\n",
            "acc_test 0.8543 f1_test: 0.8155 precision_test: 0.8150 recall_test: 0.8160\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1008 acc_train: 0.9117 acc_val: 0.8373\n",
            "Epoch: 0200 loss_train: 0.0650 acc_train: 0.9156 acc_val: 0.8392\n",
            "acc_test 0.8583 f1_test: 0.8235 precision_test: 0.8285 recall_test: 0.8190\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.2465 acc_train: 0.8626 acc_val: 0.8176\n",
            "Epoch: 0200 loss_train: 0.2723 acc_train: 0.8597 acc_val: 0.8539\n",
            "acc_test 0.8460 f1_test: 0.7974 precision_test: 0.7866 recall_test: 0.8114\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.0816 acc_train: 0.9166 acc_val: 0.8559\n",
            "Epoch: 0200 loss_train: 0.1620 acc_train: 0.8803 acc_val: 0.8422\n",
            "acc_test 0.8545 f1_test: 0.8246 precision_test: 0.8418 recall_test: 0.8127\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1189 acc_train: 0.9215 acc_val: 0.8686\n",
            "Epoch: 0200 loss_train: 0.2273 acc_train: 0.8675 acc_val: 0.8510\n",
            "acc_test 0.8574 f1_test: 0.8210 precision_test: 0.8236 recall_test: 0.8186\n",
            "Round:0005 acc_test 0.8675 f1_test: 0.8334 precision_test: 0.8351 recall_test: 0.8317\n",
            "acc:       86.83 + 0.51\n",
            "precision: 82.27 + 1.20\n",
            "recall:    83.76 + 0.64\n",
            "f1:        82.92 + 0.76\n",
            "total time: 369.5827009677887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python RF-GNN.py -dataset MGTAB -model GAT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q--tBCfWeIEv",
        "outputId": "e9b003d7-f3b0-4ae3-a34b-2e23edb8004c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(dataset='MGTAB', model='GAT', labelrate=0.1)\n",
            "relation used: followers  friends  traning 1th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1017 acc_train: 0.9156 acc_val: 0.8402\n",
            "Epoch: 0200 loss_train: 0.0472 acc_train: 0.9342 acc_val: 0.8441\n",
            "acc_test 0.8598 f1_test: 0.8175 precision_test: 0.8097 recall_test: 0.8267\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.0451 acc_train: 0.9235 acc_val: 0.8373\n",
            "Epoch: 0200 loss_train: 0.0113 acc_train: 0.9382 acc_val: 0.8275\n",
            "acc_test 0.8414 f1_test: 0.7905 precision_test: 0.7796 recall_test: 0.8047\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.0981 acc_train: 0.9254 acc_val: 0.8510\n",
            "Epoch: 0200 loss_train: 2.8025 acc_train: 0.6477 acc_val: 0.6431\n",
            "acc_test 0.8438 f1_test: 0.7928 precision_test: 0.7809 recall_test: 0.8086\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1261 acc_train: 0.9107 acc_val: 0.8559\n",
            "Epoch: 0200 loss_train: 0.0220 acc_train: 0.9342 acc_val: 0.8402\n",
            "acc_test 0.8544 f1_test: 0.8193 precision_test: 0.8267 recall_test: 0.8130\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.3662 acc_train: 0.8342 acc_val: 0.7961\n",
            "Epoch: 0200 loss_train: 0.0952 acc_train: 0.9166 acc_val: 0.8441\n",
            "acc_test 0.8504 f1_test: 0.8077 precision_test: 0.8039 recall_test: 0.8119\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1065 acc_train: 0.9087 acc_val: 0.8471\n",
            "Epoch: 0200 loss_train: 0.1214 acc_train: 0.9166 acc_val: 0.8637\n",
            "acc_test 0.8526 f1_test: 0.8185 precision_test: 0.8286 recall_test: 0.8103\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.0900 acc_train: 0.9117 acc_val: 0.8471\n",
            "Epoch: 0200 loss_train: 0.0362 acc_train: 0.9323 acc_val: 0.8373\n",
            "acc_test 0.8577 f1_test: 0.8183 precision_test: 0.8163 recall_test: 0.8204\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1236 acc_train: 0.8979 acc_val: 0.8598\n",
            "Epoch: 0200 loss_train: 0.1802 acc_train: 0.8813 acc_val: 0.8245\n",
            "acc_test 0.8461 f1_test: 0.8043 precision_test: 0.8037 recall_test: 0.8049\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.2157 acc_train: 0.8685 acc_val: 0.8186\n",
            "Epoch: 0200 loss_train: 0.0002 acc_train: 0.9460 acc_val: 0.8353\n",
            "acc_test 0.8547 f1_test: 0.8032 precision_test: 0.7858 recall_test: 0.8294\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1341 acc_train: 0.9068 acc_val: 0.8402\n",
            "Epoch: 0200 loss_train: 0.1167 acc_train: 0.9136 acc_val: 0.8529\n",
            "acc_test 0.8433 f1_test: 0.8018 precision_test: 0.8028 recall_test: 0.8008\n",
            "Round:0001 acc_test 0.8701 f1_test: 0.8320 precision_test: 0.8260 recall_test: 0.8389\n",
            "traning 2th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1820 acc_train: 0.8685 acc_val: 0.8392\n",
            "Epoch: 0200 loss_train: 0.0697 acc_train: 0.9127 acc_val: 0.8696\n",
            "acc_test 0.8630 f1_test: 0.8217 precision_test: 0.8150 recall_test: 0.8293\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1221 acc_train: 0.8950 acc_val: 0.8618\n",
            "Epoch: 0200 loss_train: 0.0301 acc_train: 0.9185 acc_val: 0.8578\n",
            "acc_test 0.8441 f1_test: 0.7830 precision_test: 0.7619 recall_test: 0.8197\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1733 acc_train: 0.8773 acc_val: 0.8510\n",
            "Epoch: 0200 loss_train: 0.0486 acc_train: 0.9225 acc_val: 0.8608\n",
            "acc_test 0.8559 f1_test: 0.8056 precision_test: 0.7899 recall_test: 0.8280\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1017 acc_train: 0.8989 acc_val: 0.8284\n",
            "Epoch: 0200 loss_train: 0.0176 acc_train: 0.9146 acc_val: 0.8304\n",
            "acc_test 0.8430 f1_test: 0.8047 precision_test: 0.8122 recall_test: 0.7983\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.1707 acc_train: 0.8921 acc_val: 0.8559\n",
            "Epoch: 0200 loss_train: 0.1168 acc_train: 0.8832 acc_val: 0.8304\n",
            "acc_test 0.8498 f1_test: 0.8019 precision_test: 0.7922 recall_test: 0.8140\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1082 acc_train: 0.9117 acc_val: 0.8598\n",
            "Epoch: 0200 loss_train: 0.0240 acc_train: 0.9225 acc_val: 0.8569\n",
            "acc_test 0.8543 f1_test: 0.8082 precision_test: 0.7987 recall_test: 0.8199\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1093 acc_train: 0.8793 acc_val: 0.8245\n",
            "Epoch: 0200 loss_train: 0.0794 acc_train: 0.8891 acc_val: 0.8294\n",
            "acc_test 0.8403 f1_test: 0.7919 precision_test: 0.7856 recall_test: 0.7992\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1520 acc_train: 0.8911 acc_val: 0.8578\n",
            "Epoch: 0200 loss_train: 0.1713 acc_train: 0.8989 acc_val: 0.8686\n",
            "acc_test 0.8403 f1_test: 0.8000 precision_test: 0.8052 recall_test: 0.7953\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1926 acc_train: 0.8616 acc_val: 0.8451\n",
            "Epoch: 0200 loss_train: 0.1632 acc_train: 0.8881 acc_val: 0.8676\n",
            "acc_test 0.8487 f1_test: 0.7981 precision_test: 0.7855 recall_test: 0.8150\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1489 acc_train: 0.8871 acc_val: 0.8490\n",
            "Epoch: 0200 loss_train: 0.0549 acc_train: 0.9127 acc_val: 0.8314\n",
            "acc_test 0.8518 f1_test: 0.7910 precision_test: 0.7664 recall_test: 0.8367\n",
            "Round:0002 acc_test 0.8728 f1_test: 0.8302 precision_test: 0.8159 recall_test: 0.8491\n",
            "traning 3th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.0722 acc_train: 0.9225 acc_val: 0.8549\n",
            "Epoch: 0200 loss_train: 0.1339 acc_train: 0.9097 acc_val: 0.8412\n",
            "acc_test 0.8507 f1_test: 0.8098 precision_test: 0.8101 recall_test: 0.8096\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1075 acc_train: 0.9195 acc_val: 0.8392\n",
            "Epoch: 0200 loss_train: 0.0393 acc_train: 0.9323 acc_val: 0.8500\n",
            "acc_test 0.8587 f1_test: 0.8226 precision_test: 0.8277 recall_test: 0.8180\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1090 acc_train: 0.9264 acc_val: 0.8245\n",
            "Epoch: 0200 loss_train: 0.0463 acc_train: 0.9274 acc_val: 0.8235\n",
            "acc_test 0.8515 f1_test: 0.8088 precision_test: 0.8058 recall_test: 0.8119\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1010 acc_train: 0.9048 acc_val: 0.8304\n",
            "Epoch: 0200 loss_train: 0.0766 acc_train: 0.9087 acc_val: 0.8314\n",
            "acc_test 0.8512 f1_test: 0.8174 precision_test: 0.8305 recall_test: 0.8075\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.0702 acc_train: 0.9185 acc_val: 0.8431\n",
            "Epoch: 0200 loss_train: 0.0064 acc_train: 0.9235 acc_val: 0.8490\n",
            "acc_test 0.8498 f1_test: 0.8119 precision_test: 0.8177 recall_test: 0.8067\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1028 acc_train: 0.9068 acc_val: 0.8363\n",
            "Epoch: 0200 loss_train: 0.1469 acc_train: 0.8871 acc_val: 0.8402\n",
            "acc_test 0.8547 f1_test: 0.8194 precision_test: 0.8282 recall_test: 0.8121\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.0342 acc_train: 0.9254 acc_val: 0.8461\n",
            "Epoch: 0200 loss_train: 0.0002 acc_train: 0.9323 acc_val: 0.8363\n",
            "acc_test 0.8657 f1_test: 0.8176 precision_test: 0.7997 recall_test: 0.8439\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1130 acc_train: 0.9097 acc_val: 0.8363\n",
            "Epoch: 0200 loss_train: 0.0384 acc_train: 0.9225 acc_val: 0.8343\n",
            "acc_test 0.8539 f1_test: 0.8158 precision_test: 0.8193 recall_test: 0.8125\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1355 acc_train: 0.8979 acc_val: 0.8451\n",
            "Epoch: 0200 loss_train: 0.2639 acc_train: 0.8018 acc_val: 0.7686\n",
            "acc_test 0.8631 f1_test: 0.8220 precision_test: 0.8158 recall_test: 0.8290\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1344 acc_train: 0.8881 acc_val: 0.8265\n",
            "Epoch: 0200 loss_train: 0.0437 acc_train: 0.9176 acc_val: 0.8294\n",
            "acc_test 0.8495 f1_test: 0.8053 precision_test: 0.8009 recall_test: 0.8101\n",
            "Round:0003 acc_test 0.8781 f1_test: 0.8430 precision_test: 0.8398 recall_test: 0.8465\n",
            "traning 4th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1482 acc_train: 0.8940 acc_val: 0.8520\n",
            "Epoch: 0200 loss_train: 0.0614 acc_train: 0.9156 acc_val: 0.8775\n",
            "acc_test 0.8531 f1_test: 0.8123 precision_test: 0.8085 recall_test: 0.8164\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1156 acc_train: 0.9107 acc_val: 0.8412\n",
            "Epoch: 0200 loss_train: 0.0167 acc_train: 0.9382 acc_val: 0.8588\n",
            "acc_test 0.8456 f1_test: 0.7996 precision_test: 0.7915 recall_test: 0.8093\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1069 acc_train: 0.9205 acc_val: 0.8549\n",
            "Epoch: 0200 loss_train: 0.0139 acc_train: 0.9401 acc_val: 0.8441\n",
            "acc_test 0.8439 f1_test: 0.7988 precision_test: 0.7927 recall_test: 0.8058\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1178 acc_train: 0.9048 acc_val: 0.8627\n",
            "Epoch: 0200 loss_train: 0.0789 acc_train: 0.9156 acc_val: 0.8667\n",
            "acc_test 0.8509 f1_test: 0.8139 precision_test: 0.8175 recall_test: 0.8106\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.0903 acc_train: 0.9136 acc_val: 0.8608\n",
            "Epoch: 0200 loss_train: 0.0624 acc_train: 0.9215 acc_val: 0.8333\n",
            "acc_test 0.8409 f1_test: 0.7880 precision_test: 0.7740 recall_test: 0.8082\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1075 acc_train: 0.9058 acc_val: 0.8549\n",
            "Epoch: 0200 loss_train: 0.0011 acc_train: 0.9372 acc_val: 0.8667\n",
            "acc_test 0.8461 f1_test: 0.8038 precision_test: 0.8007 recall_test: 0.8071\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1894 acc_train: 0.8979 acc_val: 0.8608\n",
            "Epoch: 0200 loss_train: 0.1118 acc_train: 0.8970 acc_val: 0.8373\n",
            "acc_test 0.8398 f1_test: 0.7945 precision_test: 0.7897 recall_test: 0.7999\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1040 acc_train: 0.9019 acc_val: 0.8539\n",
            "Epoch: 0200 loss_train: 0.1069 acc_train: 0.9117 acc_val: 0.8637\n",
            "acc_test 0.8447 f1_test: 0.7943 precision_test: 0.7814 recall_test: 0.8122\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1091 acc_train: 0.8989 acc_val: 0.8441\n",
            "Epoch: 0200 loss_train: 0.0403 acc_train: 0.9254 acc_val: 0.8422\n",
            "acc_test 0.8489 f1_test: 0.8062 precision_test: 0.8013 recall_test: 0.8117\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1255 acc_train: 0.9058 acc_val: 0.8657\n",
            "Epoch: 0200 loss_train: 0.1186 acc_train: 0.9185 acc_val: 0.8755\n",
            "acc_test 0.8551 f1_test: 0.8073 precision_test: 0.7926 recall_test: 0.8280\n",
            "Round:0004 acc_test 0.8621 f1_test: 0.8219 precision_test: 0.8147 recall_test: 0.8304\n",
            "traning 5th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.0761 acc_train: 0.9156 acc_val: 0.8559\n",
            "Epoch: 0200 loss_train: 0.0517 acc_train: 0.9284 acc_val: 0.8637\n",
            "acc_test 0.8424 f1_test: 0.8124 precision_test: 0.8340 recall_test: 0.7992\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.0944 acc_train: 0.9156 acc_val: 0.8529\n",
            "Epoch: 0200 loss_train: 0.0229 acc_train: 0.9244 acc_val: 0.8500\n",
            "acc_test 0.8462 f1_test: 0.8104 precision_test: 0.8186 recall_test: 0.8035\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1280 acc_train: 0.8999 acc_val: 0.8510\n",
            "Epoch: 0200 loss_train: 0.0256 acc_train: 0.9313 acc_val: 0.8588\n",
            "acc_test 0.8488 f1_test: 0.7926 precision_test: 0.7723 recall_test: 0.8265\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1096 acc_train: 0.9028 acc_val: 0.8480\n",
            "Epoch: 0200 loss_train: 0.0270 acc_train: 0.9372 acc_val: 0.8510\n",
            "acc_test 0.8330 f1_test: 0.7898 precision_test: 0.7913 recall_test: 0.7884\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.1043 acc_train: 0.9078 acc_val: 0.8676\n",
            "Epoch: 0200 loss_train: 0.0183 acc_train: 0.9441 acc_val: 0.8676\n",
            "acc_test 0.8507 f1_test: 0.8161 precision_test: 0.8247 recall_test: 0.8089\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1370 acc_train: 0.9028 acc_val: 0.8706\n",
            "Epoch: 0200 loss_train: 0.0390 acc_train: 0.9244 acc_val: 0.8686\n",
            "acc_test 0.8515 f1_test: 0.8049 precision_test: 0.7942 recall_test: 0.8187\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1184 acc_train: 0.9009 acc_val: 0.8461\n",
            "Epoch: 0200 loss_train: 0.0454 acc_train: 0.9225 acc_val: 0.8284\n",
            "acc_test 0.8549 f1_test: 0.8129 precision_test: 0.8069 recall_test: 0.8197\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1299 acc_train: 0.9078 acc_val: 0.8471\n",
            "Epoch: 0200 loss_train: 1.5212 acc_train: 0.7910 acc_val: 0.7686\n",
            "acc_test 0.8433 f1_test: 0.7998 precision_test: 0.7968 recall_test: 0.8030\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.0694 acc_train: 0.9146 acc_val: 0.8549\n",
            "Epoch: 0200 loss_train: 0.0303 acc_train: 0.9293 acc_val: 0.8598\n",
            "acc_test 0.8566 f1_test: 0.8265 precision_test: 0.8421 recall_test: 0.8152\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.0901 acc_train: 0.9293 acc_val: 0.8676\n",
            "Epoch: 0200 loss_train: 0.1084 acc_train: 0.9107 acc_val: 0.8716\n",
            "acc_test 0.8450 f1_test: 0.8100 precision_test: 0.8205 recall_test: 0.8018\n",
            "Round:0005 acc_test 0.8657 f1_test: 0.8303 precision_test: 0.8306 recall_test: 0.8300\n",
            "acc:       86.98 + 0.55\n",
            "precision: 82.54 + 0.94\n",
            "recall:    83.90 + 0.79\n",
            "f1:        83.15 + 0.68\n",
            "total time: 574.5713284015656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python RF-GNN.py -dataset MGTAB -model RGCN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv1az68YVAmd",
        "outputId": "0ba696fd-e0be-4b53-e86d-6a40bd94acd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(dataset='MGTAB', model='RGCN', labelrate=0.1)\n",
            "relation used: followers  friends  traning 1th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1780 acc_train: 0.9019 acc_val: 0.8686\n",
            "Epoch: 0200 loss_train: 0.0137 acc_train: 0.9401 acc_val: 0.8265\n",
            "acc_test 0.8583 f1_test: 0.8164 precision_test: 0.8099 recall_test: 0.8238\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.0923 acc_train: 0.9166 acc_val: 0.8451\n",
            "Epoch: 0200 loss_train: 0.0002 acc_train: 0.9323 acc_val: 0.8157\n",
            "acc_test 0.8445 f1_test: 0.7969 precision_test: 0.7887 recall_test: 0.8067\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.0474 acc_train: 0.9225 acc_val: 0.8333\n",
            "Epoch: 0200 loss_train: 0.0005 acc_train: 0.9421 acc_val: 0.8402\n",
            "acc_test 0.8332 f1_test: 0.7851 precision_test: 0.7809 recall_test: 0.7898\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1164 acc_train: 0.9097 acc_val: 0.8627\n",
            "Epoch: 0200 loss_train: 0.0064 acc_train: 0.9392 acc_val: 0.8422\n",
            "acc_test 0.8466 f1_test: 0.7996 precision_test: 0.7913 recall_test: 0.8096\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.1128 acc_train: 0.9176 acc_val: 0.8422\n",
            "Epoch: 0200 loss_train: 0.0054 acc_train: 0.9313 acc_val: 0.8314\n",
            "acc_test 0.8515 f1_test: 0.8076 precision_test: 0.8015 recall_test: 0.8146\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1406 acc_train: 0.9019 acc_val: 0.8608\n",
            "Epoch: 0200 loss_train: 0.0134 acc_train: 0.9382 acc_val: 0.8657\n",
            "acc_test 0.8564 f1_test: 0.8136 precision_test: 0.8069 recall_test: 0.8214\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1022 acc_train: 0.9019 acc_val: 0.8500\n",
            "Epoch: 0200 loss_train: 0.0106 acc_train: 0.9176 acc_val: 0.8373\n",
            "acc_test 0.8429 f1_test: 0.7953 precision_test: 0.7878 recall_test: 0.8042\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1104 acc_train: 0.9048 acc_val: 0.8539\n",
            "Epoch: 0200 loss_train: 0.0012 acc_train: 0.9362 acc_val: 0.8422\n",
            "acc_test 0.8449 f1_test: 0.7962 precision_test: 0.7867 recall_test: 0.8082\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.0787 acc_train: 0.9372 acc_val: 0.8471\n",
            "Epoch: 0200 loss_train: 0.0033 acc_train: 0.9509 acc_val: 0.8480\n",
            "acc_test 0.8390 f1_test: 0.7938 precision_test: 0.7911 recall_test: 0.7966\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1589 acc_train: 0.9058 acc_val: 0.8637\n",
            "Epoch: 0200 loss_train: 0.0086 acc_train: 0.9401 acc_val: 0.8559\n",
            "acc_test 0.8507 f1_test: 0.8038 precision_test: 0.7937 recall_test: 0.8164\n",
            "Round:0001 acc_test 0.8674 f1_test: 0.8249 precision_test: 0.8127 recall_test: 0.8405\n",
            "traning 2th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1367 acc_train: 0.9009 acc_val: 0.8529\n",
            "Epoch: 0200 loss_train: 0.0237 acc_train: 0.9264 acc_val: 0.8490\n",
            "acc_test 0.8553 f1_test: 0.8139 precision_test: 0.8109 recall_test: 0.8170\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1096 acc_train: 0.9048 acc_val: 0.8765\n",
            "Epoch: 0200 loss_train: 0.0157 acc_train: 0.9176 acc_val: 0.8510\n",
            "acc_test 0.8506 f1_test: 0.8063 precision_test: 0.8011 recall_test: 0.8122\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1313 acc_train: 0.8940 acc_val: 0.8706\n",
            "Epoch: 0200 loss_train: 0.2957 acc_train: 0.8567 acc_val: 0.8255\n",
            "acc_test 0.8551 f1_test: 0.8108 precision_test: 0.8034 recall_test: 0.8195\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1471 acc_train: 0.8960 acc_val: 0.8578\n",
            "Epoch: 0200 loss_train: 0.0315 acc_train: 0.9185 acc_val: 0.8343\n",
            "acc_test 0.8436 f1_test: 0.7979 precision_test: 0.7937 recall_test: 0.8025\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.2011 acc_train: 0.8763 acc_val: 0.8480\n",
            "Epoch: 0200 loss_train: 0.1514 acc_train: 0.8803 acc_val: 0.8392\n",
            "acc_test 0.8520 f1_test: 0.8106 precision_test: 0.8092 recall_test: 0.8120\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1979 acc_train: 0.8744 acc_val: 0.8559\n",
            "Epoch: 0200 loss_train: 0.0656 acc_train: 0.9117 acc_val: 0.8392\n",
            "acc_test 0.8449 f1_test: 0.8022 precision_test: 0.8019 recall_test: 0.8024\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1597 acc_train: 0.8960 acc_val: 0.8461\n",
            "Epoch: 0200 loss_train: 0.0301 acc_train: 0.9117 acc_val: 0.8353\n",
            "acc_test 0.8511 f1_test: 0.8039 precision_test: 0.7945 recall_test: 0.8156\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.0791 acc_train: 0.9078 acc_val: 0.8402\n",
            "Epoch: 0200 loss_train: 0.0674 acc_train: 0.9235 acc_val: 0.8539\n",
            "acc_test 0.8415 f1_test: 0.7942 precision_test: 0.7888 recall_test: 0.8004\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.2235 acc_train: 0.8656 acc_val: 0.8676\n",
            "Epoch: 0200 loss_train: 0.0889 acc_train: 0.9107 acc_val: 0.8696\n",
            "acc_test 0.8686 f1_test: 0.8302 precision_test: 0.8257 recall_test: 0.8352\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.2498 acc_train: 0.8714 acc_val: 0.8500\n",
            "Epoch: 0200 loss_train: 0.0271 acc_train: 0.9097 acc_val: 0.8304\n",
            "acc_test 0.8475 f1_test: 0.8008 precision_test: 0.7935 recall_test: 0.8094\n",
            "Round:0002 acc_test 0.8740 f1_test: 0.8353 precision_test: 0.8271 recall_test: 0.8450\n",
            "traning 3th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1821 acc_train: 0.9009 acc_val: 0.8510\n",
            "Epoch: 0200 loss_train: 0.0287 acc_train: 0.9303 acc_val: 0.8578\n",
            "acc_test 0.8594 f1_test: 0.8226 precision_test: 0.8259 recall_test: 0.8195\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1884 acc_train: 0.8891 acc_val: 0.8373\n",
            "Epoch: 0200 loss_train: 0.0300 acc_train: 0.9303 acc_val: 0.8402\n",
            "acc_test 0.8565 f1_test: 0.8147 precision_test: 0.8109 recall_test: 0.8189\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.0979 acc_train: 0.9127 acc_val: 0.8118\n",
            "Epoch: 0200 loss_train: 0.0158 acc_train: 0.9323 acc_val: 0.8147\n",
            "acc_test 0.8392 f1_test: 0.7919 precision_test: 0.7876 recall_test: 0.7966\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1181 acc_train: 0.9215 acc_val: 0.8392\n",
            "Epoch: 0200 loss_train: 0.0139 acc_train: 0.9352 acc_val: 0.8392\n",
            "acc_test 0.8602 f1_test: 0.8221 precision_test: 0.8229 recall_test: 0.8214\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.0423 acc_train: 0.9185 acc_val: 0.8363\n",
            "Epoch: 0200 loss_train: 0.0032 acc_train: 0.9284 acc_val: 0.8127\n",
            "acc_test 0.8504 f1_test: 0.8072 precision_test: 0.8041 recall_test: 0.8106\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1123 acc_train: 0.9127 acc_val: 0.8324\n",
            "Epoch: 0200 loss_train: 0.0104 acc_train: 0.9411 acc_val: 0.8265\n",
            "acc_test 0.8610 f1_test: 0.8151 precision_test: 0.8026 recall_test: 0.8313\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1086 acc_train: 0.8930 acc_val: 0.8569\n",
            "Epoch: 0200 loss_train: 0.0075 acc_train: 0.9205 acc_val: 0.8392\n",
            "acc_test 0.8680 f1_test: 0.8298 precision_test: 0.8263 recall_test: 0.8337\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1611 acc_train: 0.9009 acc_val: 0.8304\n",
            "Epoch: 0200 loss_train: 0.0164 acc_train: 0.9392 acc_val: 0.8333\n",
            "acc_test 0.8593 f1_test: 0.8177 precision_test: 0.8126 recall_test: 0.8233\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.2010 acc_train: 0.8921 acc_val: 0.8216\n",
            "Epoch: 0200 loss_train: 0.0047 acc_train: 0.9293 acc_val: 0.8235\n",
            "acc_test 0.8582 f1_test: 0.8160 precision_test: 0.8106 recall_test: 0.8220\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.0950 acc_train: 0.9176 acc_val: 0.8392\n",
            "Epoch: 0200 loss_train: 0.0050 acc_train: 0.9352 acc_val: 0.8265\n",
            "acc_test 0.8610 f1_test: 0.8219 precision_test: 0.8203 recall_test: 0.8236\n",
            "Round:0003 acc_test 0.8809 f1_test: 0.8440 precision_test: 0.8353 recall_test: 0.8543\n",
            "traning 4th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.0821 acc_train: 0.9225 acc_val: 0.8618\n",
            "Epoch: 0200 loss_train: 0.0032 acc_train: 0.9333 acc_val: 0.8598\n",
            "acc_test 0.8472 f1_test: 0.8040 precision_test: 0.7991 recall_test: 0.8094\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1207 acc_train: 0.9078 acc_val: 0.8667\n",
            "Epoch: 0200 loss_train: 0.0107 acc_train: 0.9362 acc_val: 0.8618\n",
            "acc_test 0.8549 f1_test: 0.8151 precision_test: 0.8120 recall_test: 0.8184\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1849 acc_train: 0.9078 acc_val: 0.8706\n",
            "Epoch: 0200 loss_train: 0.0117 acc_train: 0.9372 acc_val: 0.8539\n",
            "acc_test 0.8597 f1_test: 0.8220 precision_test: 0.8202 recall_test: 0.8238\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1519 acc_train: 0.8970 acc_val: 0.8578\n",
            "Epoch: 0200 loss_train: 0.0202 acc_train: 0.9235 acc_val: 0.8598\n",
            "acc_test 0.8538 f1_test: 0.8097 precision_test: 0.8007 recall_test: 0.8208\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.0945 acc_train: 0.9235 acc_val: 0.8598\n",
            "Epoch: 0200 loss_train: 0.0040 acc_train: 0.9421 acc_val: 0.8529\n",
            "acc_test 0.8571 f1_test: 0.8155 precision_test: 0.8085 recall_test: 0.8237\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1097 acc_train: 0.9107 acc_val: 0.8686\n",
            "Epoch: 0200 loss_train: 0.0263 acc_train: 0.9382 acc_val: 0.8539\n",
            "acc_test 0.8529 f1_test: 0.8030 precision_test: 0.7867 recall_test: 0.8268\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.2593 acc_train: 0.8911 acc_val: 0.8422\n",
            "Epoch: 0200 loss_train: 0.0861 acc_train: 0.9235 acc_val: 0.8569\n",
            "acc_test 0.8565 f1_test: 0.8142 precision_test: 0.8063 recall_test: 0.8234\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1505 acc_train: 0.9048 acc_val: 0.8775\n",
            "Epoch: 0200 loss_train: 0.0295 acc_train: 0.9431 acc_val: 0.8725\n",
            "acc_test 0.8555 f1_test: 0.8172 precision_test: 0.8164 recall_test: 0.8181\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1009 acc_train: 0.9097 acc_val: 0.8412\n",
            "Epoch: 0200 loss_train: 0.0040 acc_train: 0.9284 acc_val: 0.8353\n",
            "acc_test 0.8544 f1_test: 0.8163 precision_test: 0.8162 recall_test: 0.8164\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1306 acc_train: 0.8999 acc_val: 0.8667\n",
            "Epoch: 0200 loss_train: 0.0518 acc_train: 0.9225 acc_val: 0.8529\n",
            "acc_test 0.8431 f1_test: 0.7980 precision_test: 0.7922 recall_test: 0.8047\n",
            "Round:0004 acc_test 0.8718 f1_test: 0.8337 precision_test: 0.8248 recall_test: 0.8443\n",
            "traning 5th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1245 acc_train: 0.9068 acc_val: 0.8520\n",
            "Epoch: 0200 loss_train: 0.0207 acc_train: 0.9195 acc_val: 0.8647\n",
            "acc_test 0.8326 f1_test: 0.7913 precision_test: 0.7955 recall_test: 0.7875\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1530 acc_train: 0.9019 acc_val: 0.8696\n",
            "Epoch: 0200 loss_train: 0.0180 acc_train: 0.9284 acc_val: 0.8588\n",
            "acc_test 0.8539 f1_test: 0.8177 precision_test: 0.8219 recall_test: 0.8138\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1275 acc_train: 0.8989 acc_val: 0.8755\n",
            "Epoch: 0200 loss_train: 0.0093 acc_train: 0.9293 acc_val: 0.8559\n",
            "acc_test 0.8505 f1_test: 0.8130 precision_test: 0.8166 recall_test: 0.8097\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1618 acc_train: 0.9009 acc_val: 0.8618\n",
            "Epoch: 0200 loss_train: 0.0212 acc_train: 0.9392 acc_val: 0.8618\n",
            "acc_test 0.8483 f1_test: 0.8031 precision_test: 0.7955 recall_test: 0.8120\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.1076 acc_train: 0.9136 acc_val: 0.8843\n",
            "Epoch: 0200 loss_train: 0.0724 acc_train: 0.9166 acc_val: 0.8843\n",
            "acc_test 0.8505 f1_test: 0.8123 precision_test: 0.8145 recall_test: 0.8102\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1747 acc_train: 0.8960 acc_val: 0.8578\n",
            "Epoch: 0200 loss_train: 0.0174 acc_train: 0.9333 acc_val: 0.8676\n",
            "acc_test 0.8482 f1_test: 0.8019 precision_test: 0.7930 recall_test: 0.8128\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1703 acc_train: 0.9107 acc_val: 0.8539\n",
            "Epoch: 0200 loss_train: 0.0333 acc_train: 0.9333 acc_val: 0.8461\n",
            "acc_test 0.8349 f1_test: 0.7799 precision_test: 0.7667 recall_test: 0.7988\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1728 acc_train: 0.9038 acc_val: 0.8667\n",
            "Epoch: 0200 loss_train: 0.0478 acc_train: 0.9293 acc_val: 0.8696\n",
            "acc_test 0.8548 f1_test: 0.8168 precision_test: 0.8176 recall_test: 0.8161\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1536 acc_train: 0.8881 acc_val: 0.8510\n",
            "Epoch: 0200 loss_train: 0.0283 acc_train: 0.9185 acc_val: 0.8667\n",
            "acc_test 0.8415 f1_test: 0.7962 precision_test: 0.7913 recall_test: 0.8017\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.0896 acc_train: 0.9195 acc_val: 0.8686\n",
            "Epoch: 0200 loss_train: 0.0015 acc_train: 0.9284 acc_val: 0.8667\n",
            "acc_test 0.8506 f1_test: 0.8035 precision_test: 0.7925 recall_test: 0.8178\n",
            "Round:0005 acc_test 0.8705 f1_test: 0.8325 precision_test: 0.8255 recall_test: 0.8407\n",
            "acc:       87.29 + 0.45\n",
            "precision: 82.51 + 0.72\n",
            "recall:    84.50 + 0.50\n",
            "f1:        83.41 + 0.61\n",
            "total time: 525.4299037456512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/RF-GNN/\n",
        "\n",
        "# This command adds logic to save the best model weights for each round.\n",
        "!sed -i '/max_val_acc = 0/a \\        max_acc_round = 0' RF-GNN.py\n",
        "!sed -i '/if acc_val > max_val_acc:/a \\                model_path = \"/content/drive/MyDrive/RF_RGCN_MGTAB_BEST_ROUND_{}.pth\".format(num)\\n                torch.save(model.state_dict(), model_path)\\n                max_acc_round = acc_val' RF-GNN.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJdw4IbVXS3c",
        "outputId": "5129264b-3dfc-43ce-8213-92ecf1421d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RF-GNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python RF-GNN.py -dataset MGTAB -model RGCN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uK0yTnPX-mD",
        "outputId": "8feeea1b-a5cd-4712-a1c2-355f68362f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(dataset='MGTAB', model='RGCN', labelrate=0.1)\n",
            "relation used: followers  friends  traning 1th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1760 acc_train: 0.9048 acc_val: 0.8676\n",
            "Epoch: 0200 loss_train: 0.0073 acc_train: 0.9392 acc_val: 0.8333\n",
            "acc_test 0.8576 f1_test: 0.8137 precision_test: 0.8047 recall_test: 0.8247\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 3.2131 acc_train: 0.8165 acc_val: 0.7765\n",
            "Epoch: 0200 loss_train: 0.0091 acc_train: 0.9323 acc_val: 0.8314\n",
            "acc_test 0.8445 f1_test: 0.7969 precision_test: 0.7887 recall_test: 0.8067\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.2839 acc_train: 0.8469 acc_val: 0.8059\n",
            "Epoch: 0200 loss_train: 0.0058 acc_train: 0.9401 acc_val: 0.8363\n",
            "acc_test 0.8425 f1_test: 0.7925 precision_test: 0.7822 recall_test: 0.8057\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1161 acc_train: 0.9136 acc_val: 0.8637\n",
            "Epoch: 0200 loss_train: 0.0069 acc_train: 0.9372 acc_val: 0.8412\n",
            "acc_test 0.8473 f1_test: 0.7996 precision_test: 0.7902 recall_test: 0.8114\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.1155 acc_train: 0.9127 acc_val: 0.8412\n",
            "Epoch: 0200 loss_train: 0.0054 acc_train: 0.9342 acc_val: 0.8314\n",
            "acc_test 0.8517 f1_test: 0.8080 precision_test: 0.8020 recall_test: 0.8149\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1406 acc_train: 0.9019 acc_val: 0.8608\n",
            "Epoch: 0200 loss_train: 0.0133 acc_train: 0.9352 acc_val: 0.8637\n",
            "acc_test 0.8533 f1_test: 0.8136 precision_test: 0.8132 recall_test: 0.8140\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1030 acc_train: 0.8999 acc_val: 0.8520\n",
            "Epoch: 0200 loss_train: 0.0122 acc_train: 0.9107 acc_val: 0.8294\n",
            "acc_test 0.8439 f1_test: 0.7945 precision_test: 0.7844 recall_test: 0.8073\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1100 acc_train: 0.9038 acc_val: 0.8569\n",
            "Epoch: 0200 loss_train: 0.0012 acc_train: 0.9382 acc_val: 0.8422\n",
            "acc_test 0.8444 f1_test: 0.7975 precision_test: 0.7904 recall_test: 0.8059\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.0787 acc_train: 0.9372 acc_val: 0.8471\n",
            "Epoch: 0200 loss_train: 0.0033 acc_train: 0.9500 acc_val: 0.8500\n",
            "acc_test 0.8390 f1_test: 0.7938 precision_test: 0.7911 recall_test: 0.7966\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1580 acc_train: 0.9068 acc_val: 0.8627\n",
            "Epoch: 0200 loss_train: 0.0108 acc_train: 0.9382 acc_val: 0.8539\n",
            "acc_test 0.8520 f1_test: 0.8071 precision_test: 0.7994 recall_test: 0.8163\n",
            "Round:0001 acc_test 0.8696 f1_test: 0.8278 precision_test: 0.8155 recall_test: 0.8435\n",
            "traning 2th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1367 acc_train: 0.8999 acc_val: 0.8520\n",
            "Epoch: 0200 loss_train: 0.0237 acc_train: 0.9274 acc_val: 0.8471\n",
            "acc_test 0.8550 f1_test: 0.8136 precision_test: 0.8109 recall_test: 0.8166\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1087 acc_train: 0.9028 acc_val: 0.8725\n",
            "Epoch: 0200 loss_train: 0.0148 acc_train: 0.9195 acc_val: 0.8529\n",
            "acc_test 0.8509 f1_test: 0.7980 precision_test: 0.7817 recall_test: 0.8219\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1314 acc_train: 0.8950 acc_val: 0.8696\n",
            "Epoch: 0200 loss_train: 0.0072 acc_train: 0.9293 acc_val: 0.8735\n",
            "acc_test 0.8550 f1_test: 0.8090 precision_test: 0.7993 recall_test: 0.8211\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1468 acc_train: 0.8989 acc_val: 0.8569\n",
            "Epoch: 0200 loss_train: 0.0269 acc_train: 0.9205 acc_val: 0.8392\n",
            "acc_test 0.8435 f1_test: 0.7978 precision_test: 0.7936 recall_test: 0.8023\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.2011 acc_train: 0.8763 acc_val: 0.8480\n",
            "Epoch: 0200 loss_train: 0.1559 acc_train: 0.8754 acc_val: 0.8422\n",
            "acc_test 0.8523 f1_test: 0.8118 precision_test: 0.8117 recall_test: 0.8119\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1979 acc_train: 0.8744 acc_val: 0.8559\n",
            "Epoch: 0200 loss_train: 0.0663 acc_train: 0.9127 acc_val: 0.8392\n",
            "acc_test 0.8449 f1_test: 0.8022 precision_test: 0.8019 recall_test: 0.8024\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1600 acc_train: 0.8930 acc_val: 0.8441\n",
            "Epoch: 0200 loss_train: 0.0308 acc_train: 0.9097 acc_val: 0.8431\n",
            "acc_test 0.8451 f1_test: 0.7989 precision_test: 0.7935 recall_test: 0.8050\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.0694 acc_train: 0.9185 acc_val: 0.8520\n",
            "Epoch: 0200 loss_train: 0.0935 acc_train: 0.9136 acc_val: 0.8500\n",
            "acc_test 0.8548 f1_test: 0.8067 precision_test: 0.7944 recall_test: 0.8230\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.2236 acc_train: 0.8656 acc_val: 0.8676\n",
            "Epoch: 0200 loss_train: 0.0852 acc_train: 0.9087 acc_val: 0.8706\n",
            "acc_test 0.8685 f1_test: 0.8303 precision_test: 0.8262 recall_test: 0.8348\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.2498 acc_train: 0.8714 acc_val: 0.8500\n",
            "Epoch: 0200 loss_train: 0.0262 acc_train: 0.9117 acc_val: 0.8314\n",
            "acc_test 0.8475 f1_test: 0.8008 precision_test: 0.7935 recall_test: 0.8094\n",
            "Round:0002 acc_test 0.8763 f1_test: 0.8367 precision_test: 0.8255 recall_test: 0.8508\n",
            "traning 3th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1821 acc_train: 0.9009 acc_val: 0.8510\n",
            "Epoch: 0200 loss_train: 0.0305 acc_train: 0.9313 acc_val: 0.8529\n",
            "acc_test 0.8599 f1_test: 0.8221 precision_test: 0.8234 recall_test: 0.8209\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1884 acc_train: 0.8891 acc_val: 0.8373\n",
            "Epoch: 0200 loss_train: 0.0312 acc_train: 0.9303 acc_val: 0.8363\n",
            "acc_test 0.8565 f1_test: 0.8147 precision_test: 0.8109 recall_test: 0.8189\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.0967 acc_train: 0.9195 acc_val: 0.8167\n",
            "Epoch: 0200 loss_train: 0.0177 acc_train: 0.9333 acc_val: 0.8108\n",
            "acc_test 0.8392 f1_test: 0.7919 precision_test: 0.7876 recall_test: 0.7966\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1171 acc_train: 0.9225 acc_val: 0.8392\n",
            "Epoch: 0200 loss_train: 0.0111 acc_train: 0.9362 acc_val: 0.8402\n",
            "acc_test 0.8575 f1_test: 0.8194 precision_test: 0.8214 recall_test: 0.8175\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.0429 acc_train: 0.9254 acc_val: 0.8343\n",
            "Epoch: 0200 loss_train: 0.0035 acc_train: 0.9313 acc_val: 0.8275\n",
            "acc_test 0.8516 f1_test: 0.8122 precision_test: 0.8146 recall_test: 0.8099\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1124 acc_train: 0.9117 acc_val: 0.8314\n",
            "Epoch: 0200 loss_train: 0.0206 acc_train: 0.9411 acc_val: 0.8275\n",
            "acc_test 0.8594 f1_test: 0.8220 precision_test: 0.8243 recall_test: 0.8198\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1086 acc_train: 0.8930 acc_val: 0.8569\n",
            "Epoch: 0200 loss_train: 0.0074 acc_train: 0.9205 acc_val: 0.8382\n",
            "acc_test 0.8680 f1_test: 0.8298 precision_test: 0.8263 recall_test: 0.8337\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1611 acc_train: 0.9009 acc_val: 0.8304\n",
            "Epoch: 0200 loss_train: 0.0184 acc_train: 0.9372 acc_val: 0.8363\n",
            "acc_test 0.8591 f1_test: 0.8169 precision_test: 0.8112 recall_test: 0.8234\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1730 acc_train: 0.8813 acc_val: 0.8157\n",
            "Epoch: 0200 loss_train: 0.0088 acc_train: 0.9284 acc_val: 0.8304\n",
            "acc_test 0.8516 f1_test: 0.8111 precision_test: 0.8117 recall_test: 0.8105\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.0951 acc_train: 0.9195 acc_val: 0.8412\n",
            "Epoch: 0200 loss_train: 0.2111 acc_train: 0.8822 acc_val: 0.8373\n",
            "acc_test 0.8618 f1_test: 0.8204 precision_test: 0.8146 recall_test: 0.8270\n",
            "Round:0003 acc_test 0.8830 f1_test: 0.8488 precision_test: 0.8445 recall_test: 0.8536\n",
            "traning 4th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.0823 acc_train: 0.9205 acc_val: 0.8608\n",
            "Epoch: 0200 loss_train: 0.0033 acc_train: 0.9401 acc_val: 0.8686\n",
            "acc_test 0.8490 f1_test: 0.8068 precision_test: 0.8026 recall_test: 0.8114\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1203 acc_train: 0.9097 acc_val: 0.8657\n",
            "Epoch: 0200 loss_train: 0.0104 acc_train: 0.9333 acc_val: 0.8569\n",
            "acc_test 0.8558 f1_test: 0.8217 precision_test: 0.8287 recall_test: 0.8158\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1851 acc_train: 0.9078 acc_val: 0.8735\n",
            "Epoch: 0200 loss_train: 0.0085 acc_train: 0.9382 acc_val: 0.8588\n",
            "acc_test 0.8569 f1_test: 0.8121 precision_test: 0.8005 recall_test: 0.8270\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1494 acc_train: 0.9019 acc_val: 0.8608\n",
            "Epoch: 0200 loss_train: 0.0289 acc_train: 0.9205 acc_val: 0.8569\n",
            "acc_test 0.8529 f1_test: 0.8105 precision_test: 0.8042 recall_test: 0.8178\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.0936 acc_train: 0.9264 acc_val: 0.8647\n",
            "Epoch: 0200 loss_train: 0.0240 acc_train: 0.9333 acc_val: 0.8461\n",
            "acc_test 0.8588 f1_test: 0.8113 precision_test: 0.7951 recall_test: 0.8346\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1056 acc_train: 0.9127 acc_val: 0.8647\n",
            "Epoch: 0200 loss_train: 0.0161 acc_train: 0.9382 acc_val: 0.8520\n",
            "acc_test 0.8521 f1_test: 0.8035 precision_test: 0.7892 recall_test: 0.8234\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.2592 acc_train: 0.8911 acc_val: 0.8431\n",
            "Epoch: 0200 loss_train: 0.0770 acc_train: 0.9303 acc_val: 0.8667\n",
            "acc_test 0.8576 f1_test: 0.8147 precision_test: 0.8056 recall_test: 0.8259\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1520 acc_train: 0.9038 acc_val: 0.8765\n",
            "Epoch: 0200 loss_train: 0.0304 acc_train: 0.9441 acc_val: 0.8696\n",
            "acc_test 0.8619 f1_test: 0.8217 precision_test: 0.8146 recall_test: 0.8300\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1058 acc_train: 0.9078 acc_val: 0.8451\n",
            "Epoch: 0200 loss_train: 0.0040 acc_train: 0.9264 acc_val: 0.8461\n",
            "acc_test 0.8536 f1_test: 0.8152 precision_test: 0.8152 recall_test: 0.8153\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.1306 acc_train: 0.8999 acc_val: 0.8667\n",
            "Epoch: 0200 loss_train: 0.0174 acc_train: 0.9333 acc_val: 0.8510\n",
            "acc_test 0.8431 f1_test: 0.7980 precision_test: 0.7922 recall_test: 0.8047\n",
            "Round:0004 acc_test 0.8754 f1_test: 0.8369 precision_test: 0.8254 recall_test: 0.8514\n",
            "traning 5th round\n",
            "traning 1th model\n",
            "Epoch: 0100 loss_train: 0.1267 acc_train: 0.9048 acc_val: 0.8539\n",
            "Epoch: 0200 loss_train: 0.0202 acc_train: 0.9176 acc_val: 0.8657\n",
            "acc_test 0.8440 f1_test: 0.7992 precision_test: 0.7942 recall_test: 0.8050\n",
            "traning 2th model\n",
            "Epoch: 0100 loss_train: 0.1534 acc_train: 0.9048 acc_val: 0.8696\n",
            "Epoch: 0200 loss_train: 0.0166 acc_train: 0.9303 acc_val: 0.8627\n",
            "acc_test 0.8478 f1_test: 0.8079 precision_test: 0.8085 recall_test: 0.8073\n",
            "traning 3th model\n",
            "Epoch: 0100 loss_train: 0.1245 acc_train: 0.8979 acc_val: 0.8775\n",
            "Epoch: 0200 loss_train: 0.0086 acc_train: 0.9293 acc_val: 0.8637\n",
            "acc_test 0.8504 f1_test: 0.8130 precision_test: 0.8167 recall_test: 0.8096\n",
            "traning 4th model\n",
            "Epoch: 0100 loss_train: 0.1618 acc_train: 0.9009 acc_val: 0.8618\n",
            "Epoch: 0200 loss_train: 0.0220 acc_train: 0.9382 acc_val: 0.8608\n",
            "acc_test 0.8483 f1_test: 0.8031 precision_test: 0.7955 recall_test: 0.8120\n",
            "traning 5th model\n",
            "Epoch: 0100 loss_train: 0.1077 acc_train: 0.9136 acc_val: 0.8843\n",
            "Epoch: 0200 loss_train: 0.0029 acc_train: 0.9333 acc_val: 0.8647\n",
            "acc_test 0.8499 f1_test: 0.8129 precision_test: 0.8176 recall_test: 0.8087\n",
            "traning 6th model\n",
            "Epoch: 0100 loss_train: 0.1747 acc_train: 0.8960 acc_val: 0.8588\n",
            "Epoch: 0200 loss_train: 0.0168 acc_train: 0.9284 acc_val: 0.8667\n",
            "acc_test 0.8488 f1_test: 0.8063 precision_test: 0.8024 recall_test: 0.8105\n",
            "traning 7th model\n",
            "Epoch: 0100 loss_train: 0.1703 acc_train: 0.9107 acc_val: 0.8539\n",
            "Epoch: 0200 loss_train: 0.0499 acc_train: 0.9225 acc_val: 0.8520\n",
            "acc_test 0.8348 f1_test: 0.7796 precision_test: 0.7662 recall_test: 0.7988\n",
            "traning 8th model\n",
            "Epoch: 0100 loss_train: 0.1722 acc_train: 0.9058 acc_val: 0.8667\n",
            "Epoch: 0200 loss_train: 0.0297 acc_train: 0.9264 acc_val: 0.8618\n",
            "acc_test 0.8547 f1_test: 0.8152 precision_test: 0.8134 recall_test: 0.8170\n",
            "traning 9th model\n",
            "Epoch: 0100 loss_train: 0.1538 acc_train: 0.8901 acc_val: 0.8510\n",
            "Epoch: 0200 loss_train: 0.0263 acc_train: 0.9244 acc_val: 0.8618\n",
            "acc_test 0.8426 f1_test: 0.7954 precision_test: 0.7877 recall_test: 0.8048\n",
            "traning 10th model\n",
            "Epoch: 0100 loss_train: 0.0992 acc_train: 0.9166 acc_val: 0.8745\n",
            "Epoch: 0200 loss_train: 0.0627 acc_train: 0.9205 acc_val: 0.8725\n",
            "acc_test 0.8513 f1_test: 0.8053 precision_test: 0.7954 recall_test: 0.8179\n",
            "Round:0005 acc_test 0.8689 f1_test: 0.8302 precision_test: 0.8227 recall_test: 0.8390\n",
            "acc:       87.46 + 0.51\n",
            "precision: 82.67 + 0.96\n",
            "recall:    84.77 + 0.55\n",
            "f1:        83.61 + 0.73\n",
            "total time: 540.3451681137085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5zq_mH5bLKn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}